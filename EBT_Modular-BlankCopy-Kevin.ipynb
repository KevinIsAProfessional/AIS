{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Meeting Notes:\n",
    "    Modularity \n",
    "    Data issues: \n",
    "        Availability of absence data\n",
    "        Gaps between year of available data\n",
    "    Best platform for end-user tool\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Environment Set up\n",
    "\n",
    "conda create -n gee python=3\n",
    "source activate gee\n",
    "conda install -c conda-forge earthengine-api\n",
    "conda install -c anaconda pandas\n",
    "#After installing the Python GEE API, you have to run earthengine authenticate in the terminal and follow the directions. This will connect the API to your google account.\n",
    "\n",
    "#After running earthengine authenticate, you should have an environment variable set up with an authentication key, which allows you to directly initialize EE without authenticating each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import ee and required packages\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "\n",
    "from src.gee_funs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE DECLARATIONS\n",
    "\n",
    "STATE=\"Montana\"\n",
    "state_abbrevs = {\n",
    "    'Montana' : 'MT'\n",
    "}\n",
    "\n",
    "start_year = 2002\n",
    "end_year = 2018\n",
    "\n",
    "gee_path='users/kjchristensen93/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Modular Variables:\n",
    "\n",
    "#If you have a spatially thinned data set, start here after initializing ee\n",
    "\n",
    "#Taxa thinned dataset\n",
    "SThin = ee.FeatureCollection('users/kjchristensen93/EBT_data/EBT_SThin')\n",
    "#Study dates\n",
    "#Note we are limited to 2002 - 2018 due to the water year covariate \n",
    "\n",
    "### Returns a list of dates from 2002 - 2018 ###\n",
    "years = range(start_year,end_year) \n",
    "s_dates = ee.List(list(map(lambda x: ee.Date(str(x) + '-01-01'), years)))\n",
    "\n",
    "#HUC state geojson file \n",
    "HUC_state = ('./datasets/hucs/MT_HUCS.geojson')\n",
    "#Define export locations:\n",
    "#GEE yearly covariate folder\n",
    "assetId = (gee_path+'covariates/covariates_test') \n",
    "#User training csv local directory folder\n",
    "trainingdata = ('./datasets/training/')\n",
    "#User decadal image local directory folder\n",
    "decadalfolder = ('./datasets/decade/')\n",
    "#Define export naming convention? Maybe we define a function within code above for naming conventions\n",
    "\n",
    "\n",
    "#### ML Variables ####\n",
    "\n",
    "#Training Glob\n",
    "trainingglob = ('./datasets/training/*.csv')\n",
    "# trainingglob = ((trainingdata)/*.csv) will this work?\n",
    "#decadal CSV directory and naming conventions\n",
    "decade1 = ('./datasets/decade/decade1_filename.csv')\n",
    "decade2 =('./datasets/decade/decade2_filename.csv')\n",
    "#decadal predictions\n",
    "decade1_pred = ('./datasets/decade/decade1_pred_filename.csv')\n",
    "decade2_pred = ('./datasets/decade/decade2_pred_filename.csv')\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#If you need to create the spatially thinned asset...Otherwise skip to Define Modular Variables below\n",
    "#Define GEE asset/location of desired dataset (Formatted CSV must be uploaded to your GEE assets with Lat/Long columns defined \n",
    "#before starting)\n",
    "Taxa_og = ee.FeatureCollection(gee_path+'EBT_data/EBT_mfish_data_presence_heuristic')\n",
    "coll = ee.FeatureCollection(Taxa_og) \n",
    "distance = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Spatially thin locations and export to asset\n",
    "# Performs the spatial thinning algorithm on each year separately\n",
    "feats = s_dates.map(lambda x: filter_date_space(x,coll,distance))\n",
    "\n",
    "# Combine each of the resultant filtered collections\n",
    "first = ee.FeatureCollection(Taxa_og)\n",
    "spatially_thin = ee.FeatureCollection(feats.iterate(merge_coll, first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "export3 = ee.batch.Export.table.toAsset(collection = spatially_thin,\n",
    "                    description = 'EBT_SThin', # n<-------- CHANGE NAME FOR DIFFERENT DATA\n",
    "                    assetId = gee_path+'EBT_data/EBT_SThin') # <----- CHANGE Export location FOR DIFFERENT USER\n",
    "\n",
    "export3.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list dictates what years will be exported for both the Yearly Covariate Images and the Yearly Training CSVS\n",
    "# can this be changed to a list for intermitent datasets missing years? Empty outputs causes issues later on....\n",
    "import time\n",
    "# Enter start year for Y and end year for Y\n",
    "years = [str(y) for y in list(range(2002, 2005))]  ##FIXME: hardcoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export data using python API magic\n",
    "# Define geometry by changing state name so we can export the whole state at once\n",
    "states = ee.FeatureCollection(\"TIGER/2016/States\")\n",
    "#Enter state 2-digit abbreviation for study area\n",
    "geometry = states.filter(ee.Filter.eq('NAME',STATE)).geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape file containing HUC polygons\n",
    "HUC = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\n",
    "# Choose state to clip HUC by. Change Abbreviation to match dataset \n",
    "#Enter state full name for X (i.e., Illinois/ look at dataset for formats for this stuff)\n",
    "HUC_clip = HUC.filter(ee.Filter.eq('states',state_abbrevs[STATE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed observation Year as system:start_time for thinned dataset \n",
    "# We have had to add this \"Year Column\" manually to the datasets.  Make sure your dataset has correct column headings\n",
    "SThin_map = SThin.map(embedd_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Big Raster Image\n",
    "## Import assets\n",
    "# MODIS Mission\n",
    "modusGlobal = ee.ImageCollection(\"MODIS/006/MYD11A2\")\n",
    "\n",
    "# Primary Productivity\n",
    "GPP = ee.ImageCollection(\"UMT/NTSG/v2/LANDSAT/GPP\")\n",
    "\n",
    "# Surface water\n",
    "pikelSurfaceWater = ee.Image(\"JRC/GSW1_1/GlobalSurfaceWater\")\n",
    "\n",
    "# Elevation\n",
    "DEM = ee.Image(\"USGS/NED\")\n",
    "\n",
    "# Enhanced Vegetation Index and NDVI\n",
    "modusVeg = ee.ImageCollection(\"MODIS/006/MYD13A2\")\n",
    "\n",
    "# Heat Isolation Load\n",
    "CHILI = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_CHILI\")\n",
    "\n",
    "# Topographic Diversity\n",
    "topoDiversity = ee.Image(\"CSP/ERGo/1_0/Global/ALOS_topoDiversity\")\n",
    "\n",
    "# Vegetation Continuous Field product - percent tree cover, etc\n",
    "VCF = ee.ImageCollection(\"MODIS/006/MOD44B\")\n",
    "\n",
    "# Human Modification index\n",
    "gHM = ee.ImageCollection(\"CSP/HM/GlobalHumanModification\")\n",
    "\n",
    "# Climate information\n",
    "NLDAS = ee.ImageCollection(\"NASA/NLDAS/FORA0125_H002\")\n",
    "\n",
    "# Shape file containing Country Boundaries\n",
    "countries = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n",
    "\n",
    "# Shape file containing HUC polygons\n",
    "HUC = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\n",
    "\n",
    "# Dynamic Surface Water metric\n",
    "pekel_monthly_water = ee.ImageCollection(\"JRC/GSW1_2/MonthlyHistory\")\n",
    "\n",
    "# Static surface water metric\n",
    "pekel_static_water = ee.ImageCollection('JRC/GSW1_2/MonthlyRecurrence')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Select features, etc\n",
    "#========================================================\n",
    "#Rename Bands and select bands, etc\n",
    "#========================================================\n",
    "\n",
    "\n",
    "NLDAS_precip = NLDAS.select(\"total_precipitation\");\n",
    "NLDAS_temp = NLDAS.select(\"temperature\");\n",
    "NLDAS_humid = NLDAS.select(\"specific_humidity\");\n",
    "NLDAS_potEvap = NLDAS.select(\"potential_evaporation\");\n",
    "\n",
    "\n",
    "CHILI = CHILI.rename(['Heat_Insolation_Load'])\n",
    "srtmChili = CHILI.select('Heat_Insolation_Load');\n",
    "topoDiversity = topoDiversity.rename([\"Topographic_Diversity\"])\n",
    "topoDiv = topoDiversity.select(\"Topographic_Diversity\")\n",
    "footprint = ee.Image(gHM.first().select(\"gHM\"));\n",
    "\n",
    "# Surface water occurrence\n",
    "sw_occurrence = pekel_static_water\\\n",
    "                      .select('monthly_recurrence')\\\n",
    "                      .mean()\\\n",
    "                      .rename(['SurfaceWaterOccurrence'])\\\n",
    "                      .unmask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Define helper filters and lists to iterate over\n",
    "#========================================================\n",
    "# Build Lists from which to map over\n",
    "#========================================================\n",
    "# List from which absences will be built\n",
    "ee_dates = ee.List(s_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Mask features by quality control bands\n",
    "GPP_QC = GPP.map(gpp_qc);\n",
    "\n",
    "\n",
    "LST = modusGlobal.map(lst_qc) \\\n",
    "                 .select(\"LST_Day_1km\");\n",
    "\n",
    "modusVeg_QC = modusVeg.map(modusQC)\n",
    "EVI = modusVeg_QC.select(\"EVI\")\n",
    "NDVI = modusVeg_QC.select(\"NDVI\")\n",
    "\n",
    "VCF_qc = VCF.map(VCFqc)\n",
    "\n",
    "\n",
    "#========================================================\n",
    "# Define Point Joins such that each HUC contains a list of observational data:\n",
    "#========================================================\n",
    "distFilter = ee.Filter.intersects(**{\n",
    "  'leftField': '.geo', \n",
    "  'rightField': '.geo', \n",
    "  'maxError': 100\n",
    "});\n",
    "\n",
    "pointJoin = ee.Join.saveAll(**{\n",
    "  'matchesKey': 'Points',\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Annual Cube function\n",
    "#========================================================\n",
    "# \"Builder Function\" -- processes each annual variable into a list of images\n",
    "#========================================================\n",
    "\n",
    "def build_annual_cube(d):\n",
    "    # Set start and end dates for filtering time dependent predictors (SR, NDVI, Phenology)\n",
    "      # Advance startDate by 1 to begin with to account for water year (below)\n",
    "    startDate = (ee.Date(d).advance(1.0,'year').millis()) ## FIXME: Why do we advance a year? this give 2003-2019 instead of 2002-2018\n",
    "    endDate = ee.Date(d).advance(2.0,'year').millis()\n",
    "\n",
    "  #========================================================\n",
    "  #Define function to compute seasonal information for a given variable\n",
    "  #========================================================\n",
    "    def add_seasonal_info(imgCol,name,bandName):\n",
    "        winter = imgCol.filterDate(winter_start,winter_end)\n",
    "        spring = imgCol.filterDate(spring_start,spring_end)\n",
    "        summer = imgCol.filterDate(summer_start,summer_end)\n",
    "        fall = imgCol.filterDate(fall_start,fall_end)\n",
    "\n",
    "        winter_tot = winter.sum()\n",
    "        spring_tot = spring.sum()\n",
    "        summer_tot = summer.sum()\n",
    "        fall_tot = fall.sum()\n",
    "\n",
    "        winter_max = winter.max()\n",
    "        winter_min = winter.min()\n",
    "        spring_max = spring.max()\n",
    "        spring_min = spring.min()\n",
    "        summer_max = summer.max()\n",
    "        summer_min = summer.min()\n",
    "        fall_max = fall.max()\n",
    "        fall_min = fall.min()\n",
    "\n",
    "        winter_diff = winter_max.subtract(winter_min)\n",
    "        spring_diff = spring_max.subtract(spring_min)\n",
    "        summer_diff = summer_max.subtract(summer_min)\n",
    "        fall_diff = fall_max.subtract(fall_min)\n",
    "\n",
    "        names = ['winter_total'+name,'spring_total'+name,'summer_total'+name,\n",
    "                      'fall_total'+name]\n",
    "\n",
    "        return winter_tot.addBands([spring_tot,summer_tot,fall_tot]) \\\n",
    "                         .rename(names)\n",
    "\n",
    "  # Set up Seasonal dates for precip, seasonal predictors\n",
    "    winter_start = ee.Date(startDate)\n",
    "    winter_end = ee.Date(startDate).advance(3,'month')\n",
    "    spring_start = ee.Date(startDate).advance(3,'month')\n",
    "    spring_end = ee.Date(startDate).advance(6,'month')\n",
    "    summer_start = ee.Date(startDate).advance(6,'month')\n",
    "    summer_end = ee.Date(startDate).advance(9,'month')\n",
    "    fall_start = ee.Date(startDate).advance(9,'month')\n",
    "    fall_end = ee.Date(endDate)\n",
    "\n",
    "  # Aggregate seasonal info for each variable of interest (potEvap neglected purposefully)\n",
    "    seasonal_precip = add_seasonal_info(NLDAS_precip,\"Precip\",\"total_precipitation\")\n",
    "    seasonal_temp = add_seasonal_info(NLDAS_temp,\"Temp\",\"temperature\")\n",
    "    seasonal_humid = add_seasonal_info(NLDAS_humid,\"Humidity\",\"specific_humidity\")\n",
    "\n",
    "    waterYear_start = ee.Date(startDate).advance(10,'month')\n",
    "    waterYear_end = waterYear_start.advance(1,'year')\n",
    "\n",
    "  #========================================================\n",
    "  # Aggregate Other Covariates\n",
    "  #========================================================\n",
    "\n",
    "  # Vegetative Continuous Fields\n",
    "    meanVCF = VCF.filterDate(startDate, endDate)\\\n",
    "                 .mean()\n",
    "    \n",
    "#     VCF_qc.filterDate(startDate, endDate) \\\n",
    "#                       .mean()\n",
    "\n",
    "  # Filter Precip by water year to get total precip annually\n",
    "\n",
    "    waterYearTot = NLDAS_precip.filterDate(waterYear_start,waterYear_end) \\\n",
    "                                 .sum()\n",
    "\n",
    "  # Find mean EVI per year:\n",
    "    maxEVI = EVI.filterDate(startDate,endDate) \\\n",
    "                  .mean() \\\n",
    "                  .rename(['Mean_EVI'])\n",
    "\n",
    "  #Find mean NDVI per year:\n",
    "    maxNDVI = NDVI.filterDate(startDate,endDate) \\\n",
    "                    .mean() \\\n",
    "                    .rename([\"Mean_NDVI\"])\n",
    "\n",
    "  # Find flashiness per year by taking a Per-pixel Standard Deviation:\n",
    "    flashiness_yearly = ee.Image(pekel_monthly_water.filterDate(startDate,endDate) \\\n",
    "                                                      .reduce(ee.Reducer.sampleStdDev()) \\\n",
    "                                                      .select([\"water_stdDev\"])) \\\n",
    "                                                      .rename(\"Flashiness\")\n",
    "\n",
    "  # Find max LST per year:\n",
    "    maxLST = LST.max().rename([\"Max_LST_Annual\"])\n",
    "\n",
    "  # Find mean GPP per year:\n",
    "    maxGPP = GPP_QC.filterDate(startDate,endDate) \\\n",
    "                      .mean() \\\n",
    "                      .rename(['Mean_GPP','QC'])\n",
    "\n",
    "  # All banded images that don't change over time\n",
    "    static_input_bands = sw_occurrence.addBands(DEM.select(\"elevation\")) \\\n",
    "                                          .addBands(srtmChili) \\\n",
    "                                          .addBands(topoDiv) \\\n",
    "                                          .addBands(footprint)\n",
    "\n",
    "  # Construct huge banded image\n",
    "    banded_image = static_input_bands \\\n",
    "                          .addBands(srcImg = maxLST, names = [\"Max_LST_Annual\"]) \\\n",
    "                          .addBands(srcImg = maxGPP, names = [\"Mean_GPP\"]) \\\n",
    "                          .addBands(srcImg =  maxNDVI, names = [\"Mean_NDVI\"]) \\\n",
    "                          .addBands(srcImg = maxEVI, names = [\"Mean_EVI\"]) \\\n",
    "                          .addBands(meanVCF.select(\"Percent_Tree_Cover\")) \\\n",
    "                          .addBands(seasonal_precip) \\\n",
    "                          .addBands(flashiness_yearly) \\\n",
    "                          .set(\"system:time_start\",startDate)\n",
    "\n",
    "    return banded_image.unmask()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#========================================================\n",
    "# Run covariate algorithm and build a list of images\n",
    "# with each image corresponding to each year and each band corresponding to each covariate\n",
    "#========================================================\n",
    "\n",
    "# Image Collection\n",
    "banded_images = ee.ImageCollection(ee_dates.map(build_annual_cube))\n",
    "\n",
    "# List form\n",
    "banded_images_list = ee.List(ee_dates.map(build_annual_cube))\n",
    "\n",
    "annual_stacks = ee.FeatureCollection(banded_images.map(lambda x: reduce_HUCS(x, SThin_map, HUC_clip)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#Skip this step if you already have them stored in GEE\n",
    "#Export Yearly Covariate Images\n",
    "\n",
    "# Export each image within the for loop\n",
    "for i,y in zip(range(len(years)), years):\n",
    "    print(\"Starting\", y)\n",
    "    img = ee.Image(ee.List(banded_images_list).get(ee.Number(i)))\n",
    "    export = ee.batch.Export.image.toAsset(image = img,\n",
    "                    description = 'covariate_'+y,\n",
    "                    assetId = (assetId) +y, \n",
    "                    region = ee.Geometry(geometry),\n",
    "                    scale =  100,\n",
    "                    maxPixels = 1e13)\n",
    "    export.start()\n",
    "    \n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "\n",
    "    # Wait for 30 seconds so that the export['state'] gives insightful information\n",
    "    time.sleep(15)\n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    \n",
    "    \n",
    "    # If this status is \"RUNNING\", then there are no egretious syntax errors. \n",
    "    # However, it is still possible that these export commands fail after more than 30 seconds.\n",
    "    # In that case, it is likely that there is a Computation Time Out Error (remember exporting the annual stacks)\n",
    "    time.sleep(15)\n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Start Here if you have yearly covariates created\n",
    "\n",
    "#Export training CSVs\n",
    "## Reduce Regions from existing images\n",
    "\n",
    "# COVARIATE IMAGES  \n",
    "\n",
    "path = assetId\n",
    "years = range(start_year, 2017)\n",
    "images = list(map(lambda x: ee.Image(path + str(x)), years))\n",
    "banded_images_asset_list = ee.List(images)\n",
    "\n",
    "for i in range(len(years)):\n",
    "    print(\"Starting\", start_year+i)\n",
    "    \n",
    "    img = ee.Image(banded_images_asset_list.get(i))\n",
    "    data = reduce_HUCS(img,SThin_map,HUC_clip) \n",
    "    \n",
    "    ## PYTHON API MAGIC!! LOOK HERE\n",
    "    my_csv = pd.DataFrame([x['properties'] for x in data.getInfo()['features']])\n",
    "    \n",
    "    # From there, we can write it directly to our directory and stitch it together afterwards\n",
    "    my_csv.to_csv((trainingdata) + str(2002+i) + '.csv', index=False) \n",
    "    print(\"Finished\", start_year+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export the information that we will use to project habitat suitability. \n",
    "#Decades were convenient for RBT, but not other taxa with less data/ we can change.\n",
    "# Change to match dataset\n",
    "\n",
    "#Can we set this up such that this is automatically defined when we define the year range above?\n",
    "first_decade = ee.ImageCollection.fromImages(images[0:7]).mean()\n",
    "\n",
    "#second_decade = ee.ImageCollection.fromImages(images[7:]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export these data as csvs\n",
    "first_decade_img = ee.Image(first_decade)\n",
    "\n",
    "first_csv = first_decade_img.reduceRegions(**{\n",
    "                              'collection': HUC_clip,\n",
    "                              'reducer': ee.Reducer.mean(),\n",
    "                              'crs': 'EPSG:4326',\n",
    "                              'scale': 100,\n",
    "                              'tileScale': 16})\n",
    "\n",
    "#PYTHON API MAGIC!! LOOK HERE\n",
    "first_decade_data = pd.DataFrame([x['properties'] for x in first_csv.getInfo()['features']])\n",
    "\n",
    "# From there, we can write it directly to our directory and stitch it together afterwards\n",
    "#maybe we should think about 2 and 5 year bins due to limitations of datasets for some taxa/ to make more useful for managers\n",
    "first_decade_data.to_csv(decade1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Export these data as csvs for second decade if dataset contains that many sampling years\n",
    "second_decade_img = ee.Image(second_decade)\n",
    "\n",
    "second_csv = second_decade_img.reduceRegions(**{\n",
    "                              'collection': HUC_clip,\n",
    "                              'reducer': ee.Reducer.mean(),\n",
    "                              'crs': 'EPSG:4326',\n",
    "                              'scale': 100,\n",
    "                              'tileScale': 16})\n",
    "\n",
    "## PYTHON API MAGIC!! LOOK HERE\n",
    "second_decade_data = pd.DataFrame([x['properties'] for x in second_csv.getInfo()['features']])\n",
    "\n",
    "# From there, we can write it directly to our directory and stitch it together afterwards\n",
    "second_decade_data.to_csv(decade2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "1374.44px",
    "right": "20px",
    "top": "59.9943px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
