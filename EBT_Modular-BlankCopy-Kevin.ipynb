{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Meeting Notes:\n",
    "    Modularity \n",
    "    Data issues: \n",
    "        Availability of absence data\n",
    "        Gaps between year of available data\n",
    "    Best platform for end-user tool\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Environment Set up\n",
    "\n",
    "conda create -n gee python=3\n",
    "source activate gee\n",
    "conda install -c conda-forge earthengine-api\n",
    "conda install -c anaconda pandas\n",
    "#After installing the Python GEE API, you have to run earthengine authenticate in the terminal and follow the directions. This will connect the API to your google account.\n",
    "\n",
    "#After running earthengine authenticate, you should have an environment variable set up with an authentication key, which allows you to directly initialize EE without authenticating each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import ee and required packages\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "\n",
    "from src.gee_funs import *\n",
    "import src.build_annual_cube as bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE DECLARATIONS\n",
    "\n",
    "STATE=\"Montana\"\n",
    "state_abbrevs = {\n",
    "    'Montana' : 'MT'\n",
    "}\n",
    "\n",
    "start_year = 2002\n",
    "end_year = 2018\n",
    "\n",
    "gee_path='users/kjchristensen93/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Modular Variables:\n",
    "\n",
    "#If you have a spatially thinned data set, start here after initializing ee\n",
    "\n",
    "#Taxa thinned dataset\n",
    "SThin = ee.FeatureCollection('users/kjchristensen93/EBT_data/EBT_SThin')\n",
    "#Study dates\n",
    "#Note we are limited to 2002 - 2018 due to the water year covariate \n",
    "\n",
    "### Returns a list of dates from 2002 - 2018 ###\n",
    "years = range(start_year,end_year) \n",
    "s_dates = ee.List(list(map(lambda x: ee.Date(str(x) + '-01-01'), years)))\n",
    "\n",
    "#HUC state geojson file \n",
    "HUC_state = ('./datasets/hucs/MT_HUCS.geojson')\n",
    "#Define export locations:\n",
    "#GEE yearly covariate folder\n",
    "assetId = (gee_path+'covariates/covariates_test') \n",
    "#User training csv local directory folder\n",
    "trainingdata = ('./datasets/training/')\n",
    "#User decadal image local directory folder\n",
    "decadalfolder = ('./datasets/decade/')\n",
    "#Define export naming convention? Maybe we define a function within code above for naming conventions\n",
    "\n",
    "\n",
    "#### ML Variables ####\n",
    "\n",
    "#Training Glob\n",
    "trainingglob = ('./datasets/training/*.csv')\n",
    "# trainingglob = ((trainingdata)/*.csv) will this work?\n",
    "#decadal CSV directory and naming conventions\n",
    "decade1 = ('./datasets/decade/decade1_filename.csv')\n",
    "decade2 =('./datasets/decade/decade2_filename.csv')\n",
    "#decadal predictions\n",
    "decade1_pred = ('./datasets/decade/decade1_pred_filename.csv')\n",
    "decade2_pred = ('./datasets/decade/decade2_pred_filename.csv')\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#If you need to create the spatially thinned asset...Otherwise skip to Define Modular Variables below\n",
    "#Define GEE asset/location of desired dataset (Formatted CSV must be uploaded to your GEE assets with Lat/Long columns defined \n",
    "#before starting)\n",
    "Taxa_og = ee.FeatureCollection(gee_path+'EBT_data/EBT_mfish_data_presence_heuristic')\n",
    "coll = ee.FeatureCollection(Taxa_og) \n",
    "distance = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Spatially thin locations and export to asset\n",
    "# Performs the spatial thinning algorithm on each year separately\n",
    "feats = s_dates.map(lambda x: filter_date_space(x,coll,distance))\n",
    "\n",
    "# Combine each of the resultant filtered collections\n",
    "first = ee.FeatureCollection(Taxa_og)\n",
    "spatially_thin = ee.FeatureCollection(feats.iterate(merge_coll, first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "export3 = ee.batch.Export.table.toAsset(collection = spatially_thin,\n",
    "                    description = 'EBT_SThin', # n<-------- CHANGE NAME FOR DIFFERENT DATA\n",
    "                    assetId = gee_path+'EBT_data/EBT_SThin') # <----- CHANGE Export location FOR DIFFERENT USER\n",
    "\n",
    "export3.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list dictates what years will be exported for both the Yearly Covariate Images and the Yearly Training CSVS\n",
    "# can this be changed to a list for intermitent datasets missing years? Empty outputs causes issues later on....\n",
    "import time\n",
    "# Enter start year for Y and end year for Y\n",
    "years = [str(y) for y in list(range(2002, 2005))]  ##FIXME: hardcoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export data using python API magic\n",
    "# Define geometry by changing state name so we can export the whole state at once\n",
    "states = ee.FeatureCollection(\"TIGER/2016/States\")\n",
    "#Enter state 2-digit abbreviation for study area\n",
    "geometry = states.filter(ee.Filter.eq('NAME',STATE)).geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape file containing HUC polygons\n",
    "HUC = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\n",
    "# Choose state to clip HUC by. Change Abbreviation to match dataset \n",
    "#Enter state full name for X (i.e., Illinois/ look at dataset for formats for this stuff)\n",
    "HUC_clip = HUC.filter(ee.Filter.eq('states',state_abbrevs[STATE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed observation Year as system:start_time for thinned dataset \n",
    "# We have had to add this \"Year Column\" manually to the datasets.  Make sure your dataset has correct column headings\n",
    "SThin_map = SThin.map(embedd_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Define helper filters and lists to iterate over\n",
    "#========================================================\n",
    "# Build Lists from which to map over\n",
    "#========================================================\n",
    "# List from which absences will be built\n",
    "ee_dates = ee.List(s_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#========================================================\n",
    "# Run covariate algorithm and build a list of images\n",
    "# with each image corresponding to each year and each band corresponding to each covariate\n",
    "#========================================================\n",
    "\n",
    "banded_images_list = bac.build_all_cubes(start_year, end_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Skip this step if you already have them stored in GEE\n",
    "#Export Yearly Covariate Images\n",
    "\n",
    "# Export each image within the for loop\n",
    "for i,y in zip(range(len(years)), years):\n",
    "    print(\"Starting\", y)\n",
    "    img = ee.Image(ee.List(banded_images_list).get(ee.Number(i)))\n",
    "    export = ee.batch.Export.image.toAsset(image = img,\n",
    "                    description = 'covariate_'+y,\n",
    "                    assetId = ('users/mstokowski/covariates/covariates_test') +y, \n",
    "                    region = ee.Geometry(geometry),\n",
    "                    scale =  100,\n",
    "                    maxPixels = 1e13)\n",
    "    export.start()\n",
    "    \n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "\n",
    "    # Wait for 30 seconds so that the export['state'] gives insightful information\n",
    "    time.sleep(15)\n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    \n",
    "    \n",
    "    # If this status is \"RUNNING\", then there are no egretious syntax errors. \n",
    "    # However, it is still possible that these export commands fail after more than 30 seconds.\n",
    "    # In that case, it is likely that there is a Computation Time Out Error (remember exporting the annual stacks)\n",
    "    time.sleep(15)\n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Start Here if you have yearly covariates created\n",
    "\n",
    "#Export training CSVs\n",
    "## Reduce Regions from existing images\n",
    "\n",
    "# COVARIATE IMAGES  \n",
    "\n",
    "path = assetId\n",
    "years = range(start_year, 2005)\n",
    "images = list(map(lambda x: ee.Image(path + str(x)), years))\n",
    "banded_images_asset_list = ee.List(images)\n",
    "\n",
    "for i in range(len(years)):\n",
    "    print(\"Starting\", start_year+i)\n",
    "    \n",
    "    img = ee.Image(banded_images_asset_list.get(i))\n",
    "    data = reduce_HUCS(img,SThin_map,HUC_clip) \n",
    "    \n",
    "    ## PYTHON API MAGIC!! LOOK HERE\n",
    "    my_csv = pd.DataFrame([x['properties'] for x in data.getInfo()['features']])\n",
    "    \n",
    "    # From there, we can write it directly to our directory and stitch it together afterwards\n",
    "    my_csv.to_csv((trainingdata) + str(2002+i) + '.csv', index=False) \n",
    "    print(\"Finished\", start_year+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export the information that we will use to project habitat suitability. \n",
    "#Decades were convenient for RBT, but not other taxa with less data/ we can change.\n",
    "# Change to match dataset\n",
    "\n",
    "#Can we set this up such that this is automatically defined when we define the year range above?\n",
    "first_decade = ee.ImageCollection.fromImages(images[0:7]).mean()\n",
    "\n",
    "#second_decade = ee.ImageCollection.fromImages(images[7:]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export these data as csvs\n",
    "first_decade_img = ee.Image(first_decade)\n",
    "\n",
    "first_csv = first_decade_img.reduceRegions(**{\n",
    "                              'collection': HUC_clip,\n",
    "                              'reducer': ee.Reducer.mean(),\n",
    "                              'crs': 'EPSG:4326',\n",
    "                              'scale': 100,\n",
    "                              'tileScale': 16})\n",
    "\n",
    "#PYTHON API MAGIC!! LOOK HERE\n",
    "first_decade_data = pd.DataFrame([x['properties'] for x in first_csv.getInfo()['features']])\n",
    "\n",
    "# From there, we can write it directly to our directory and stitch it together afterwards\n",
    "#maybe we should think about 2 and 5 year bins due to limitations of datasets for some taxa/ to make more useful for managers\n",
    "first_decade_data.to_csv(decade1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Export these data as csvs for second decade if dataset contains that many sampling years\n",
    "second_decade_img = ee.Image(second_decade)\n",
    "\n",
    "second_csv = second_decade_img.reduceRegions(**{\n",
    "                              'collection': HUC_clip,\n",
    "                              'reducer': ee.Reducer.mean(),\n",
    "                              'crs': 'EPSG:4326',\n",
    "                              'scale': 100,\n",
    "                              'tileScale': 16})\n",
    "\n",
    "## PYTHON API MAGIC!! LOOK HERE\n",
    "second_decade_data = pd.DataFrame([x['properties'] for x in second_csv.getInfo()['features']])\n",
    "\n",
    "# From there, we can write it directly to our directory and stitch it together afterwards\n",
    "second_decade_data.to_csv(decade2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.ml_funs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "1374.44px",
    "right": "20px",
    "top": "59.9943px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
