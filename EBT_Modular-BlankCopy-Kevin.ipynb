{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Environment Set up\n",
    "\n",
    "conda create -n gee python=3\n",
    "source activate gee\n",
    "conda install -c conda-forge earthengine-api\n",
    "conda install -c anaconda pandas\n",
    "#After installing the Python GEE API, you have to run earthengine authenticate in the terminal and follow the directions. This will connect the API to your google account.\n",
    "\n",
    "#After running earthengine authenticate, you should have an environment variable set up with an authentication key, which allows you to directly initialize EE without authenticating each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import ee and required packages\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "from src.gee_funs import *\n",
    "import src.build_annual_cube as bac\n",
    "import src.preprocess_points as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE DECLARATIONS\n",
    "\n",
    "STATE=\"Montana\"\n",
    "state_abbrevs = {\n",
    "    'Montana' : 'MT'\n",
    "}\n",
    "\n",
    "# years to export for both the Yearly Covariate Images\n",
    "# and the Yearly Training CSVS\n",
    "# Note we are limited to 2002 - 2018 due to the water year covariate  \n",
    "start_year = 2002\n",
    "end_year = 2018\n",
    "years = range(start_year, end_year)\n",
    "years_strings = [str(y) for y in years]\n",
    "\n",
    "gee_path='users/kjchristensen93/'\n",
    "ais_point_path = gee_path + 'EBT_data/EBT_mfish_data_presence_heuristic'\n",
    "ais_thinned_point_path = ais_point_path + '_sthin'\n",
    "\n",
    "#Define export locations:\n",
    "#GEE yearly covariate folder\n",
    "assetId = (gee_path+'covariates/covariates') \n",
    "#User training csv local directory folder\n",
    "trainingdata = ('./datasets/training/')\n",
    "trainingglob = trainingdata+'*.csv'\n",
    "#decadal CSV directory and naming conventions\n",
    "decade1 = ('./datasets/decade/decade1.csv')\n",
    "decade2 =('./datasets/decade/decade2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you need to create the spatially thinned asset...Otherwise skip to Define Modular Variables below\n",
    "#Define GEE asset/location of desired dataset \n",
    "#(Formatted CSV must be uploaded to your GEE assets with Lat/Long columns defined before starting)\n",
    "if False:\n",
    "    pp.spatially_thin(ais_point_path, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a spatially thinned data set, start here after initializing ee\n",
    "# embed observation Year as system:start_time for thinned dataset \n",
    "# We have had to add this \"Year Column\" manually to the datasets.  \n",
    "# Make sure your dataset has correct column headings\n",
    "SThin = ee.FeatureCollection(ais_thinned_point_path).map(embed_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define geometry by changing state name so we can export the whole state at once\n",
    "state_geometry = ee.FeatureCollection(\"TIGER/2016/States\").filter(ee.Filter.eq('NAME',STATE)).geometry()\n",
    "\n",
    "# Choose state to clip HUC by. Change Abbreviation to match dataset \n",
    "#Enter state full name for X (i.e., Illinois/ look at dataset for formats for this stuff)\n",
    "HUC_clip = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\").filter(ee.Filter.eq('states',state_abbrevs[STATE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Skip this step if you already have them stored in GEE\n",
    "#Export Yearly Covariate Images\n",
    "\n",
    "#========================================================\n",
    "# Run covariate algorithm and build a list of images\n",
    "# with each image corresponding to each year and each band corresponding to each covariate\n",
    "#========================================================\n",
    "banded_images_list = bac.build_all_cubes(start_year, end_year)\n",
    "\n",
    "# Export each image within the for loop\n",
    "for i,y in zip(range(len(years_strings)), years_strings):\n",
    "    print(\"Starting\", y)\n",
    "    img = ee.Image(banded_images_list.get(ee.Number(i)))\n",
    "    export = ee.batch.Export.image.toAsset(\n",
    "        image = img,\n",
    "        description = 'covariates'+y,\n",
    "        assetId = assetId + y, \n",
    "        region = ee.Geometry(state_geometry),\n",
    "        scale =  100,\n",
    "        maxPixels = 1e13)\n",
    "    export.start()\n",
    "    \n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "\n",
    "    # Wait for 30 seconds so that the export['state'] gives insightful information\n",
    "    time.sleep(15)\n",
    "    # TODO better handle status messages\n",
    "    # while (export.status()['state'] == 'READY'):\n",
    "    #    time.sleep(15)\n",
    "        \n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    \n",
    "    # If this status is \"RUNNING\", then there are no egretious syntax errors. \n",
    "    # However, it is still possible that these export commands fail after more than 30 seconds.\n",
    "    # In that case, it is likely that there is a Computation Time Out Error (remember exporting the annual stacks)\n",
    "    time.sleep(15)\n",
    "    print(y,\"status:    \", export.status()['state'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Start Here if you have yearly covariates created\n",
    "\n",
    "#Export training CSVs\n",
    "## Reduce Regions from existing images\n",
    "\n",
    "# COVARIATE IMAGES  \n",
    "images = list(map(lambda x: ee.Image(assetId + str(x)), years))\n",
    "\n",
    "for i in range(len(years)):\n",
    "    print(\"Starting\", start_year+i)\n",
    "    \n",
    "    data = reduce_HUCS(images[i],SThin,HUC_clip) \n",
    "    \n",
    "    ## PYTHON API MAGIC!! LOOK HERE\n",
    "    my_csv = pd.DataFrame([x['properties'] for x in data.getInfo()['features']])\n",
    "    \n",
    "    # From there, we can write it directly to our directory and stitch it together afterwards\n",
    "    my_csv.to_csv((trainingdata) + str(2002+i) + '.csv', index=False) \n",
    "    print(\"Finished\", start_year+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export the information that we will use to project habitat suitability. \n",
    "#Decades were convenient for RBT, but not other taxa with less data/ we can change.\n",
    "# Change to match dataset\n",
    "# maybe we should think about 2 and 5 year bins due to limitations of datasets for some \n",
    "# taxa / to make more useful for managers\n",
    "\n",
    "write_predictions_input_csv(images[:7], decade1, HUC_clip)  \n",
    "\n",
    "# write_predictions_input_csv(images[7:], decade2, HUC_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.ml_funs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "1374.44px",
    "right": "20px",
    "top": "59.9943px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
